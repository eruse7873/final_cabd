{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e99f27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12286704",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_third=pd.read_csv('first_third_of_data.csv')\n",
    "second_third=pd.read_csv('second_third_of_data.csv')\n",
    "last_third=pd.read_csv('last_third_of_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947252f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.concat([first_third, second_third,last_third], ignore_index=True)\n",
    "data.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090ac78",
   "metadata": {},
   "source": [
    "Start with webscraping all of the New York Time recipe pages that are referenced in the Kaggle Dataset. The data that we are interested in is the recipe ratings and the number of ingredients that each recipe requires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca09479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_urls(end, urls):\n",
    "    base_url='https://cooking.nytimes.com/recipes/'+end\n",
    "    urls.append(base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9d0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_url=[]\n",
    "\n",
    "group_df=data.groupby(['recipe_id','recipe_name']).sum()\n",
    "group_df=pd.DataFrame(group_df)\n",
    "group_df=group_df.reset_index()\n",
    "\n",
    "\n",
    "id_dict={}\n",
    "\n",
    "for row in range(len(group_df)):\n",
    "    recipe_id=str(group_df.loc[row,'recipe_id'])\n",
    "    id_dict[recipe_id]=[]\n",
    "    recipe_name=group_df.loc[row,'recipe_name']\n",
    "    recipe_name=recipe_name.replace(\" \",\"-\")\n",
    "    end_url.append(recipe_id+'-'+recipe_name)\n",
    "    \n",
    "urls=[]    \n",
    "for end in end_url:\n",
    "    create_urls(end, urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d045b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_recipe_page(main_url):\n",
    "    soup = BeautifulSoup(requests.get(main_url).text, \"html.parser\")\n",
    "    \n",
    "    #Scrape recipe rating\n",
    "    try:\n",
    "        rating_text=soup.find(\"script\", type=\"application/ld+json\").text\n",
    "        begin_pos=rating_text.find(\"ratingValue\")\n",
    "        rating_text=rating_text[begin_pos:]\n",
    "        end_pos=rating_text.find(\":\")\n",
    "        rating=rating_text[end_pos+1:end_pos+2]\n",
    "    except:\n",
    "        rating=-1\n",
    "\n",
    "    #Scrape the number of ingredients\n",
    "    num_ingredients=len(soup.find_all(\"span\", class_=\"ingredient-name\"))\n",
    "    \n",
    "    #Add back to dict to later join with dataframe\n",
    "    pos_num=re.search(r\"\\d\", main_url)\n",
    "    if pos_num:\n",
    "        end_num=main_url[pos_num.start():].find('-')\n",
    "        if len(id_dict[main_url[pos_num.start():pos_num.start()+end_num]])<2:\n",
    "            id_dict[main_url[pos_num.start():pos_num.start()+end_num]].extend([num_ingredients,rating])\n",
    "        else:\n",
    "            pass  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47924b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    scrape_recipe_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3959618",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_rating_df=pd.DataFrame.from_dict(id_dict, orient='index',\n",
    "                       columns=['num_ingredients', 'rating'])\n",
    "\n",
    "ingredient_rating_df.index.name='recipe_id'      \n",
    "ingredient_rating_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f7dad7",
   "metadata": {},
   "source": [
    "Write webscraped data to a csv file so we do not have to re-run webscraper everytime we open notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ad5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "ingredient_rating_df.to_csv('ingredient_rating_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
